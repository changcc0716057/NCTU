{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3250ab514154a14864f8870cc17ad5412f044af73ab5f34b9fc68c1b9ee31df3"
   }
  },
  "interpreter": {
   "hash": "3250ab514154a14864f8870cc17ad5412f044af73ab5f34b9fc68c1b9ee31df3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "\n",
    "epsilon = 10 ** (-6)\n",
    "nAttribute = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file and preprocess datas\n",
    "def load_data(filename, partition=(8,2)):\n",
    "    # read files\n",
    "    origin_data = pd.read_csv(filename, sep=\",\", header=None).to_numpy()\n",
    "    n_data = origin_data.shape[0]\n",
    "    \n",
    "    # shuffle the data\n",
    "    for i in range(0,10):\n",
    "        np.random.shuffle(origin_data)\n",
    "\n",
    "    # calculate where to spilt data\n",
    "    spiltpoint = round(n_data * partition[0] / (sum(partition)))\n",
    "    train_x, train_y, test_x, test_y = None, None, None, None\n",
    "\n",
    "\n",
    "    # we need to spilt different dataset with different way\n",
    "    if filename == \"glass.data\":\n",
    "        train_x = origin_data[0:spiltpoint, 1:-1]\n",
    "        train_y = origin_data[0:spiltpoint, -1]\n",
    "        test_x = origin_data[spiltpoint:n_data, 1:-1]\n",
    "        test_y = origin_data[spiltpoint:n_data, -1]\n",
    "    elif filename == \"iris.data\" or filename == \"ionosphere\":\n",
    "        train_x = origin_data[0:spiltpoint, 0:-1]\n",
    "        train_y = origin_data[0:spiltpoint, -1]\n",
    "        test_x = origin_data[spiltpoint:n_data, 0:-1]\n",
    "        test_y = origin_data[spiltpoint:n_data, -1]\n",
    "    else:\n",
    "        train_x = origin_data[0:spiltpoint, 1:]\n",
    "        train_y = origin_data[0:spiltpoint, 0]\n",
    "        test_x = origin_data[spiltpoint:n_data, 1:]\n",
    "        test_y = origin_data[spiltpoint:n_data, 0]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Gini's impurity\n",
    "def Gini(labels):\n",
    "    _ , counts = np.unique(labels, return_counts=True)\n",
    "    impurity = sum([(count/labels.shape[0]) ** 2 for count in counts])\n",
    "    return 1 - impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, depth=0):\n",
    "        self.FalseNode = None\n",
    "        self.TrueNode = None\n",
    "        self.leaf = True\n",
    "        self.majorlabel = None\n",
    "        self.attribute = None\n",
    "        self.threshold = None\n",
    "        self.depth = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART:\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "\n",
    "    # Given a threshold, spilt the data into two set by this threshold\n",
    "    def spiltNode(self, datas, attribute, threshold):\n",
    "        # FSetId for indices of false set; TsetId for indices of true set\n",
    "        FSetID = []\n",
    "        TSetID = []\n",
    "\n",
    "        # According to the type of data, split the data in different way \n",
    "        if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "            for i in range(0,len(datas[:,attribute])):\n",
    "                if (datas[:,attribute][i] < threshold):\n",
    "                    FSetID.append(i)\n",
    "                else:\n",
    "                    TSetID.append(i)\n",
    "        else:\n",
    "            for i in range(0,len(datas[:,attribute])):\n",
    "                if (datas[:,attribute][i] != threshold):\n",
    "                    FSetID.append(i)\n",
    "                else:\n",
    "                    TSetID.append(i)\n",
    "        return FSetID, TSetID\n",
    "\n",
    "    # recursively build the CART\n",
    "    # stop when we cannot reduce the impurity\n",
    "    def buildCART(self, curNode, datas, labels, attrilist, max_depth, min_impurity_decrease=0.0, min_samples_split=2, criterion=Gini):\n",
    "        \"\"\"\n",
    "        max_depth: The maximum depth of the tree\n",
    "        min_impurity_decrease: A node will be split if this split induces a decrease of the impurity greater than or equal to this value\n",
    "        min_samples_split: The minimum number of samples required to split an internal node\n",
    "        criterion: The function to measure the quality of a split\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if we meet the limit\n",
    "        if curNode.depth >= max_depth or labels.shape[0] <= min_samples_split:\n",
    "            key , counts = np.unique(labels, return_counts=True)\n",
    "            curNode.majorlabel = key[np.argmax(counts)]\n",
    "            return\n",
    "\n",
    "        # if the label is unique in this node\n",
    "        if np.unique(labels).shape[0] == 1:\n",
    "            curNode.majorlabel = labels[0]\n",
    "            return\n",
    "\n",
    "        # initialize \n",
    "        parent_imp = criterion(labels)  \n",
    "        max_impurity_decrease = 0.0\n",
    "        best_attribute, best_threshold = None, None\n",
    "\n",
    "        # reset min_impurity_decrease\n",
    "        min_impurity_decrease = max(min_impurity_decrease, epsilon)        \n",
    "\n",
    "        # find the best attribute for reducing most impurity\n",
    "        for curAtt in attrilist:\n",
    "\n",
    "            # collect all possible threshold\n",
    "            threslist = np.unique(datas[:,curAtt])\n",
    "            if isinstance(datas[0][curAtt], int) or isinstance(datas[0][curAtt], float):\n",
    "                threslist = [(threslist[i-1]+threslist[i])/2 for i in range(1,len(threslist))] \n",
    "\n",
    "            # find the best threshold for reducing most impurity\n",
    "            for threshold in threslist:\n",
    "                FSetID, TSetID = self.spiltNode(datas, curAtt, threshold)\n",
    "                ratio = len(FSetID) / labels.shape[0]\n",
    "                impurity_decrease = parent_imp - ratio * criterion(labels[FSetID]) - (1 - ratio) * criterion(labels[TSetID])\n",
    "\n",
    "                # we get better attribute and threshold to spilt the node\n",
    "                if impurity_decrease > max_impurity_decrease:\n",
    "                    max_impurity_decrease = impurity_decrease\n",
    "                    best_attribute, best_threshold = curAtt, threshold\n",
    "\n",
    "        # the reduction of impurity is more than limit\n",
    "        if max_impurity_decrease > min_impurity_decrease:\n",
    "            Best_FSetID, Best_TSetID = self.spiltNode(datas, best_attribute, best_threshold)\n",
    "            curNode.FalseNode, curNode.TrueNode = Node(curNode.depth+1), Node(curNode.depth+1)\n",
    "            curNode.attribute, curNode.threshold = best_attribute, best_threshold\n",
    "            curNode.leaf = False  # we can spilt more\n",
    "            self.buildCART(curNode.FalseNode, datas[Best_FSetID], labels[Best_FSetID], attrilist, max_depth, min_impurity_decrease, min_samples_split, criterion)\n",
    "            self.buildCART(curNode.TrueNode, datas[Best_TSetID], labels[Best_TSetID], attrilist, max_depth, min_impurity_decrease, min_samples_split, criterion)\n",
    "        # the reduction cannot meet the limit, so this node is leaf and should compute majorlabel\n",
    "        else:\n",
    "            key , counts = np.unique(labels, return_counts=True)\n",
    "            curNode.majorlabel = key[np.argmax(counts)]\n",
    "\n",
    "    def train(self, datas, labels, max_depth=None, max_features=\"auto\", bootstrap=True, \\\n",
    "        min_impurity_decrease=0.0, min_samples_split=2, criterion=Gini):\n",
    "        if max_depth == None:\n",
    "            max_depth = 10 ** 9\n",
    "\n",
    "        # Attribute Bagging\n",
    "        if bootstrap == True:\n",
    "            attributeID = np.random.choice(a=nAttribute, size=max_features, replace=False)\n",
    "        else:\n",
    "            attributeID = [i for i in range(0, nAttribute)]\n",
    "        self.buildCART(self.root, datas, labels, attributeID, max_depth,\\\n",
    "             min_impurity_decrease, min_samples_split, criterion)\n",
    "\n",
    "    # Use to predict the label of testcase\n",
    "    def predict(self, testcase):\n",
    "        curNode = self.root\n",
    "        while (not curNode.leaf):\n",
    "            if isinstance(curNode.threshold, int) or isinstance(curNode.threshold, float):\n",
    "                if testcase[curNode.attribute] < curNode.threshold:\n",
    "                    curNode = curNode.FalseNode\n",
    "                else:\n",
    "                    curNode = curNode.TrueNode\n",
    "            else:\n",
    "                if testcase[curNode.attribute] == curNode.threshold:\n",
    "                    curNode = curNode.FalseNode\n",
    "                else:\n",
    "                    curNode = curNode.TrueNode\n",
    "        return curNode.majorlabel\n",
    "\n",
    "    #Use to calculate the accuracy of testcases\n",
    "    def cal_accuracy(self, testcases, labels):\n",
    "        ncase = len(labels)\n",
    "        correct = [int(self.predict(testcases[i]) == labels[i]) for i in range(0,ncase)]\n",
    "        return float(sum(correct)) / ncase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, max_features=\"auto\", max_samples=None, bootstrap=True, min_impurity_decrease=0.0, min_samples_split=2, criterion=Gini):\n",
    "        self.CARTrees = []\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.max_samples = max_samples\n",
    "        self.bootstrap = bootstrap\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def train(self, datas, labels):\n",
    "        # According to different input, give the corresponding number of features\n",
    "        if self.max_features == \"auto\" or self.max_features == \"sqrt\":\n",
    "            self.max_features = math.sqrt(nAttribute)\n",
    "        elif self.max_features == \"log2\":\n",
    "            self.max_features = math.log2(nAttribute)\n",
    "        elif type(self.max_features) == float:\n",
    "            self.max_features = self.max_features * nAttribute\n",
    "        elif self.max_features == None:\n",
    "            self.max_features = nAttribute\n",
    "\n",
    "        if self.max_samples == None:\n",
    "            self.max_samples = datas.shape[0]\n",
    "        elif type(self.max_samples) == float:\n",
    "            self.max_samples = self.max_samples * datas.shape[0]\n",
    "\n",
    "        # ensure that the number of  samples and features is less than or equal to the original size\n",
    "        self.max_samples = min(round(self.max_samples), datas.shape[0])\n",
    "        self.max_features = min(round(self.max_features), nAttribute)\n",
    "\n",
    "        # Constuction the trees in the forest, and train the CARTs\n",
    "        for i in range(0, self.n_estimators):\n",
    "            tree = CART()\n",
    "            # tree bagging\n",
    "            if self.bootstrap == True:\n",
    "                sampleID = np.random.choice(a=datas.shape[0], size=self.max_samples, replace=False)\n",
    "            else:\n",
    "                sampleID = [i for i in range(0, datas.shape[0])]\n",
    "\n",
    "            tree.train(datas[sampleID], labels[sampleID], self.max_depth, self.max_features, self.bootstrap, self.min_impurity_decrease, self.min_samples_split, self.criterion)\n",
    "            self.CARTrees.append(tree)\n",
    "    # Use to predict the label of testcase\n",
    "    def predict(self, testcase):\n",
    "        predict_labels = np.array([tree.predict(testcase) for tree in self.CARTrees])\n",
    "        key , counts = np.unique(predict_labels, return_counts=True)\n",
    "        return key[np.argmax(counts)]\n",
    "    #Use to calculate the accuracy of testcases\n",
    "    def cal_accuracy(self, testcases, labels):\n",
    "        ncase = len(labels)\n",
    "        correct = [int(self.predict(testcases[i]) == labels[i]) for i in range(0,ncase)]\n",
    "        return float(sum(correct)) / ncase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "filename: breast-cancer.data n_esitmators: (5, 5) \nTrain Accuracy: 0.6671328671328671 \nTest Accuracy: 0.6713286713286711 \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-41c4c5f100f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[1;31m#a = time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mRF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sqrt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mRF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcal_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcal_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-4f82ccc4711c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, datas, labels)\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0msampleID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msampleID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msampleID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCARTrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# Use to predict the label of testcase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-5578665248b4>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, datas, labels, max_depth, max_features, bootstrap, min_impurity_decrease, min_samples_split, criterion)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mattributeID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnAttribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         self.buildCART(self.root, datas, labels, attributeID, max_depth,\\\n\u001b[0m\u001b[0;32m     98\u001b[0m              min_impurity_decrease, min_samples_split, criterion)\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-5578665248b4>\u001b[0m in \u001b[0;36mbuildCART\u001b[1;34m(self, curNode, datas, labels, attrilist, max_depth, min_impurity_decrease, min_samples_split, criterion)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_attribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# we can spilt more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildCART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFalseNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_FSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_FSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrilist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildCART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrueNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_TSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_TSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrilist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# the reduction cannot meet the limit, so this node is leaf and should compute majorlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-5578665248b4>\u001b[0m in \u001b[0;36mbuildCART\u001b[1;34m(self, curNode, datas, labels, attrilist, max_depth, min_impurity_decrease, min_samples_split, criterion)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_attribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# we can spilt more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildCART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFalseNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_FSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_FSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrilist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildCART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrueNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_TSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_TSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrilist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# the reduction cannot meet the limit, so this node is leaf and should compute majorlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-5578665248b4>\u001b[0m in \u001b[0;36mbuildCART\u001b[1;34m(self, curNode, datas, labels, attrilist, max_depth, min_impurity_decrease, min_samples_split, criterion)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_attribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# we can spilt more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildCART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFalseNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_FSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_FSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrilist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildCART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrueNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_TSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_TSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrilist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# the reduction cannot meet the limit, so this node is leaf and should compute majorlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-5578665248b4>\u001b[0m in \u001b[0;36mbuildCART\u001b[1;34m(self, curNode, datas, labels, attrilist, max_depth, min_impurity_decrease, min_samples_split, criterion)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# we can spilt more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildCART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFalseNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_FSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_FSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrilist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildCART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrueNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_TSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_TSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrilist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;31m# the reduction cannot meet the limit, so this node is leaf and should compute majorlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-5578665248b4>\u001b[0m in \u001b[0;36mbuildCART\u001b[1;34m(self, curNode, datas, labels, attrilist, max_depth, min_impurity_decrease, min_samples_split, criterion)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_attribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# we can spilt more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildCART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFalseNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_FSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_FSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrilist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildCART\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrueNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_TSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBest_TSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrilist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# the reduction cannot meet the limit, so this node is leaf and should compute majorlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-5578665248b4>\u001b[0m in \u001b[0;36mbuildCART\u001b[1;34m(self, curNode, datas, labels, attrilist, max_depth, min_impurity_decrease, min_samples_split, criterion)\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mFSetID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTSetID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspiltNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurAtt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFSetID\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[0mimpurity_decrease\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent_imp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mFSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTSetID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;31m# we get better attribute and threshold to spilt the node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-9977366be453>\u001b[0m in \u001b[0;36mGini\u001b[1;34m(labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compute Gini's impurity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mGini\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimpurity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mimpurity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    filenames = [\"breast-cancer.data\", \"glass.data\", \"ionosphere.data\", \"wine.data\"]\n",
    "    n_f = [(5,5),(6,4),(7,3),(8,2),(9,1)]\n",
    "\n",
    "    for filename in filenames:\n",
    "        for n_es in n_f:\n",
    "            train = 0\n",
    "            test = 0\n",
    "            for i in range(0,10):\n",
    "                train_x, train_y, test_x, test_y = load_data(filename, n_es)\n",
    "                nAttribute = train_x.shape[1]\n",
    "                attrilist = [i for i in range(0, nAttribute)]\n",
    "\n",
    "                #a = time.time()\n",
    "                RF = RandomForest(n_estimators=100, max_depth=12, max_features=\"sqrt\", max_samples=100, bootstrap=True, min_impurity_decrease=epsilon, min_samples_split=2)\n",
    "                RF.train(train_x, train_y)\n",
    "                train_accuracy = RF.cal_accuracy(train_x, train_y)\n",
    "                test_accuracy = RF.cal_accuracy(test_x, test_y)\n",
    "                #b = time.time()\n",
    "                train += train_accuracy\n",
    "                test += test_accuracy\n",
    "\n",
    "            print(\"filename:\", filename, \"n_esitmators:\", n_es, '\\n', end='')\n",
    "            print(\"Train Accuracy:\", train/10, '\\n', end='')\n",
    "            print(\"Test Accuracy:\", test/10, '\\n', end='')\n",
    "            #print(\"Used Time:\", b-a, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}